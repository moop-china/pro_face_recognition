{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于InsightFace的人脸识别\n",
    "![基于InsightFace的人脸识别](img/1.jpg \"基于InsightFace的人脸识别\")\n",
    "\n",
    "## 一、综述  \n",
    "\n",
    "这篇教程我们将介绍用InsightFace进行人脸检测的基本原理和流程。  \n",
    "[InsightFace](https://github.com/deepinsight/insightface/tree/master/RetinaFace)是目前深度学习领域SOTA（最先进的，State Of The Art）的人脸分析项目，其中人脸检测（和校正）由RetinaFace实现；而人脸识别由ArcFace实现。  \n",
    "\n",
    "工业级的人脸识别需要包含4个步骤：  \n",
    "   * 人脸检测（detection），将图片中的人脸检测切割出来，并计算关键点（landmark）用于人脸矫正。  \n",
    "   * 人脸矫正（alignment），检测到的人脸可能有各种角度、表情，矫正可以将人脸调整到接近标准模板，提高识别率。  \n",
    "   * 姿态过滤，利用姿态预估模型计算人脸的姿态，过滤掉偏转角度过大的人脸。  \n",
    "   * 人脸识别，计算矫正过的人脸的特征码（embedding），计算它与底库特征码的距离，当最小距离小于阀值时，认为识别成功，数据底库特征码对应的身份ID。  \n",
    "   \n",
    "![人脸识别的流程](img/3.png \"人脸识别的流程\")\n",
    "   \n",
    "## 二、检测  \n",
    "\n",
    "人脸检测是把人脸从图片中用矩形框分割出来，这里调用RetinaNet进行处理。  \n",
    "首先是导入所需的Python库，准备好数据，并定义一些Helper函数。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import datetime\n",
    "from multiprocessing import  Process\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(''), 'RetinaFace'))\n",
    "from retinaface import RetinaFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_picure_path = os.path.join(os.path.abspath(''), 'data/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_scale(img_shape, scales):\n",
    "    target_size, max_size = scales\n",
    "    \n",
    "    img_size_min = np.min(img_shape[0:2])\n",
    "    img_size_max = np.max(img_shape[0:2])\n",
    "    \n",
    "    img_scale = float(target_size) / float(img_size_min)\n",
    "    \n",
    "    if np.round(img_scale * img_size_max) > max_size:\n",
    "        img_scale = float(max_size) / float(img_size_max)\n",
    "        \n",
    "    return img_scale\n",
    "\n",
    "def draw_on_img(img, faces, landmarks=None):\n",
    "    for i in range(faces.shape[0]):\n",
    "        box = faces[i].astype(np.int)\n",
    "        \n",
    "        color = (0, 0, 255)\n",
    "        cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "        \n",
    "        if landmarks is not None:\n",
    "            landmark5 = landmarks[i].astype(np.int)\n",
    "            \n",
    "            for l in range(landmark5.shape[0]):\n",
    "                color = (0, 255, 0)\n",
    "                cv2.circle(img, (landmark5[l][0], landmark5[l][1]), 1, color, 2)\n",
    "                \n",
    "    plt.imshow(img[..., ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来需要设置参数并初始化检测模型。  \n",
    "要注意当gpu_id小于0的时候，MxNet会自动选用CPU进行计算。  \n",
    "另外RetinaFace最后一个参数用于选择[Anchor](https://www.quora.com/What-does-an-anchor-mean-in-object-detection)的大小，会影响不同尺寸人脸检测的精度。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "score_threshold = 0.94\n",
    "image_scales = [720, 1024]\n",
    "\n",
    "# init detector - mxnet selects cpu if gpu_id < 0\n",
    "gpu_id = -1\n",
    "\n",
    "detector = RetinaFace('../../share/data/model/R50', 0, gpu_id, 'net3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后读出图片并检测就可以了：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list input pics\n",
    "entries = os.listdir(input_picure_path)\n",
    "\n",
    "for entry in entries:\n",
    "    arr = entry.split('.')\n",
    "\n",
    "    if len(arr) > 1 and arr[1] == 'jpg':\n",
    "        # read image\n",
    "        img_path = os.path.join(input_picure_path, entry)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        img_scale = get_img_scale(img.shape, image_scales)\n",
    "        \n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        faces, landmarks = detector.detect(\n",
    "            img,\n",
    "            score_threshold,\n",
    "            scales=[img_scale],\n",
    "            do_flip=False\n",
    "        )\n",
    "        \n",
    "        end_time = datetime.datetime.now()\n",
    "        time_diff = end_time - start_time\n",
    "        \n",
    "        print('{}: spent {} sec(s), detected {} face(s)'.format(\n",
    "            entry,\n",
    "            time_diff.total_seconds(),\n",
    "            faces.shape[0]\n",
    "        ))\n",
    "        \n",
    "        draw_on_img(img, faces, landmarks=landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 课堂小实验  \n",
    "在人脸检测中，我们得到了人脸框和五个关键点，它们的数据格式是怎样的呢？请在下方代码框内，编写程序打印输出它们，并给出你的解释：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、矫正  \n",
    "\n",
    "检测到的人脸有各种姿态和角度，如果根据Landmark（关键点）加以矫正，可以提高识别正确率。  \n",
    "矫正算法的思路是，定义一个标准关键点模板，计算检测到的关键点到标准模板的变换，并对人脸图像执行相同的变换，则实现了对人脸图像的矫正。  \n",
    "如果图片中有多张人脸，我们只识别最大的一张人脸，这在人脸打卡、闸机等系统是常见处理。对于不同的应用，可以采用不同的过滤规则。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_face(img, faces, landmarks):\n",
    "    max_size = 0\n",
    "    max_box= []\n",
    "    max_landmark = []\n",
    "\n",
    "    if len(faces) != 0 or len(landmarks) != 0:\n",
    "        # find out the max face\n",
    "        for i in range(faces.shape[0]):\n",
    "            box = faces[i]\n",
    "            size = (box[0] - box[2]) * (box[1] - box[3])\n",
    "            \n",
    "            if size > max_size:\n",
    "                max_box = box\n",
    "                max_landmark  = landmarks[i].astype(np.int)\n",
    "                max_size = size\n",
    "                \n",
    "        # config and template\n",
    "        image_size = [112, 112]\n",
    "        src = np.array([\n",
    "            [30.2946, 51.6963],\n",
    "            [65.5318, 51.5014],\n",
    "            [48.0252, 71.7366],\n",
    "            [33.5493, 92.3655],\n",
    "            [62.7299, 92.2041]], dtype=np.float32)\n",
    "        \n",
    "        # template was created for 96x112 pic\n",
    "        # adjust point position for 112x112\n",
    "        if image_size[1] == 112:\n",
    "            src[:, 0] += 8.0\n",
    "            \n",
    "        # OK, transform\n",
    "        warped = None\n",
    "\n",
    "        if max_landmark is not None:\n",
    "            tform = transform.SimilarityTransform()\n",
    "            tform.estimate(max_landmark, src)\n",
    "            M = tform.params[0:2, :]\n",
    "            warped = cv2.warpAffine(img, M, (image_size[1], image_size[0]), borderValue=0.0)\n",
    "            \n",
    "            plt.imshow(warped[..., ::-1])\n",
    "            plt.show()\n",
    "            \n",
    "            return warped\n",
    "\n",
    "warped_faces = []\n",
    "\n",
    "for idx, (img, faces, landmarks) in enumerate(zip(img_list, bbox_list, landmark_list)):\n",
    "    warped_face = wrap_face(img, faces, landmarks)\n",
    "    \n",
    "    warped_faces.append(warped_face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、识别\n",
    "\n",
    "人脸识别问题的最大的困难在于，相对于普通的分类任务，人脸(作为类别)是数量不定并且非常多的。  \n",
    "为了解决这个问题，通常人脸识别模型本身就是分类模型，但是训练方法上与普通分类有很大区别。  \n",
    "\n",
    "我们人类进行人脸识别的时候，可以在内心衡量两张脸之间的相似度，同一张脸的不同图片，它们是比较相似的；而不同脸的图片则差别较大。  \n",
    "同样的道理，我们也可以用神经网络来计算图片的特征向量，并且比较特征之间的相似度。相似度的计算，可以用数学公式表示成距离函数。  \n",
    "\n",
    "因此，人脸识别模型是利用Metric Learning的方法进行训练的。比如Triplet Loss，训练的时候，网络会趋向于拉近来自同一张脸的图片间的距离、同时推远来自不同的脸的图片间的距离。  \n",
    "显然，欧式距离并不是唯一可用的距离函数，ArcFace就提出了更好的人脸特征距离。  \n",
    "\n",
    "ArcFace是一个角度距离，如果我们把两个图片的特征向量进行归一化，那么它们之间的距离，就等于特征向量的夹角。  \n",
    "而归一化向量的点积就等于向量夹角的余弦，所以我们对向量点积取一个反余弦就可以得到夹角弧度，这就是ArcFace名字的由来。  \n",
    "那么为什么我们要把欧式距离变成角度距离呢？这是因为我们并不关心同一张脸不同图片的区别，所以我们把同一张脸的所有图片都映射到一个角度就足够了。  \n",
    "![ArcFace](img/2.png \"ArcFace\")\n",
    "\n",
    "好了，理论知识已经足够了，让我们继续一些实际的工作，首先需要建立特征底库。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractFeature:\n",
    "    def __init__(self, prefix, epoch, gpu_id=-1):\n",
    "        sym, arg_params, aux_params = mx.model.load_checkpoint(prefix, epoch)\n",
    "        \n",
    "        if gpu_id < 0:\n",
    "            self.mod = mx.mod.Module(symbol=sym, context=mx.cpu(0))\n",
    "        else:\n",
    "            self.mod = mx.mod.Module(symbol=sym, context=mx.gpu(gpu_id))\n",
    "\n",
    "        # 获取网络结构\n",
    "        internals = self.mod.symbol.get_internals()\n",
    "\n",
    "        # 获取从输入到特征值层的模型\n",
    "        feature_net = internals[\"fc1_output\"]\n",
    "\n",
    "        if gpu_id < 0:\n",
    "            self.feature_model = mx.module.Module(symbol=feature_net, context=mx.cpu(0))\n",
    "        else:\n",
    "            self.feature_model = mx.module.Module(symbol=feature_net, context=mx.gpu(gpu_id))\n",
    "\n",
    "        data_shapes = [('data', (1, 3, 112, 112))]\n",
    "        self.feature_model.bind(data_shapes=data_shapes)\n",
    "\n",
    "        # 上面只是定义了结构，这里设置特征模型的参数为Inception_BN的\n",
    "        self.feature_model.set_params(\n",
    "            arg_params=arg_params,\n",
    "            aux_params=aux_params,\n",
    "            allow_missing=False\n",
    "        )\n",
    "\n",
    "    def bufferDecode(self, str_image):\n",
    "        data = np.fromstring(str_image, dtype='uint8')\n",
    "        return cv2.imdecode(data, 1)\n",
    "\n",
    "    def do_flip(self, data):\n",
    "        for idx in xrange(data.shape[0]):\n",
    "            data[idx, :, :] = np.fliplr(data[idx, :, :])\n",
    "\n",
    "    def ExtractFeature(self, image, b_flip):\n",
    "        if isinstance(image, str):\n",
    "            imgsrc = cv2.imread(image)\n",
    "        else:\n",
    "            imgsrc = image\n",
    "            \n",
    "        img = cv2.resize(imgsrc, (112, 112), interpolation=cv2.INTER_CUBIC)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img = np.swapaxes(img, 0, 2)\n",
    "        img = np.swapaxes(img, 1, 2)\n",
    "\n",
    "        embedding = None\n",
    "\n",
    "        fliplist = []\n",
    "        \n",
    "        if b_flip == True:\n",
    "            fliplist = [0, 1]\n",
    "        else:\n",
    "            fliplist = [0]\n",
    "\n",
    "        for flipid in fliplist:\n",
    "            _img = np.copy(img)\n",
    "            if flipid == 1:\n",
    "                self.do_flip(_img)\n",
    "\n",
    "            Batch = namedtuple('Batch', ['data'])\n",
    "            data = Batch([mx.nd.array(np.array([_img]))])\n",
    "\n",
    "            # 输出特征\n",
    "            self.feature_model.forward(data, is_train=False)\n",
    "            _embedding = self.feature_model.get_outputs()[0].asnumpy()\n",
    "            if embedding is None:\n",
    "                embedding = _embedding\n",
    "            else:\n",
    "                embedding += _embedding\n",
    "\n",
    "        _norm = np.linalg.norm(embedding)\n",
    "        embedding /= _norm\n",
    "\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "recog_model_prefix = '../../share/data/model/feature'\n",
    "model_epoch = 0\n",
    "\n",
    "# mxnet selects cpu if gpu_id < 0\n",
    "extractor = ExtractFeature(recog_model_prefix, model_epoch, gpu_id=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list db pics\n",
    "entries = os.listdir(db_picture_path)\n",
    "\n",
    "id_list = {}\n",
    "\n",
    "for entry in entries:\n",
    "    arr = entry.split('.')\n",
    "    \n",
    "    if len(arr) > 1 and arr[1] == 'jpg':\n",
    "        img, bboxes, landmarks = detect(db_picture_path, entry)\n",
    "        wraped_face = wrap_face(img, bboxes, landmarks)\n",
    "        \n",
    "        # get embedding\n",
    "        embedding = extractor.ExtractFeature(wraped_face, False)\n",
    "        \n",
    "        # save embedding\n",
    "        id_list[arr[0]] = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 课堂小实验  \n",
    "请试着计算底库中任意2个特征向量的欧式距离吧！（提示，用[numpy.linalg.norm](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html)）  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "终于，万事俱备，只欠——特征比对："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相似度计算函数\n",
    "def calc_similarity(Feature1, Feature2):\n",
    "    return np.dot(Feature1, Feature2) / (np.linalg.norm(Feature1) * np.linalg.norm(Feature2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, face in enumerate(warped_faces):\n",
    "    face_feature = extractor.ExtractFeature(face, False)\n",
    "\n",
    "    face_scores = []\n",
    "\n",
    "    for name in id_list.keys():\n",
    "        id_feature = id_list[name]\n",
    "\n",
    "        similarity = calc_similarity(face_feature.squeeze(), id_feature.squeeze())\n",
    "        face_scores.append(similarity)\n",
    "\n",
    "    max_score = np.max(face_scores)\n",
    "    max_id = np.argmax(face_scores)\n",
    "\n",
    "    if max_score > 0.00:\n",
    "        name = id_list.keys()[max_id]\n",
    "    else:\n",
    "        name = 'Unknown'\n",
    "\n",
    "    print('pic: {}, id: {}, similarity: {}'.format(i, name, max_score))\n",
    "    plt.imshow(face[..., ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、课后作业  \n",
    "\n",
    "利用人脸相似度算法，我们可以构建一个“名人鉴定机”，输入一张你的图片，输出和你长得最像的名人的脸，快去收集名人照片，用我们学到的知识做起来吧！  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gluon)",
   "language": "python",
   "name": "gluon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
